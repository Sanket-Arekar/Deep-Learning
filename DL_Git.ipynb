{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5bf8cd43369d40b4ab6ba017896ecff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_953029952ede491e8bb20594ad46f1d3",
              "IPY_MODEL_4fc8a26d9b204729b82b313c49d3b8a9",
              "IPY_MODEL_45ca5e4557504af4a71aee721b80cf8b"
            ],
            "layout": "IPY_MODEL_26de027d23964277b6a88387578a3f82"
          }
        },
        "953029952ede491e8bb20594ad46f1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e8713ebc884816b2930712e5c70564",
            "placeholder": "​",
            "style": "IPY_MODEL_3ffdc4c8fc3544d0a281c774a8dd3545",
            "value": "Epoch 1: 100%"
          }
        },
        "4fc8a26d9b204729b82b313c49d3b8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c8e9e160ca4422fa5076691b3e69028",
            "max": 2320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d83aa579aaf043b28f48cbb3dd617799",
            "value": 2320
          }
        },
        "45ca5e4557504af4a71aee721b80cf8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd9db356d88e4d868cd37bd68c07da2e",
            "placeholder": "​",
            "style": "IPY_MODEL_300bcc735f524e9f8d01cb118545a95e",
            "value": " 2320/2320 [1:00:13&lt;00:00,  1.31s/it, loss=2.34]"
          }
        },
        "26de027d23964277b6a88387578a3f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e8713ebc884816b2930712e5c70564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ffdc4c8fc3544d0a281c774a8dd3545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c8e9e160ca4422fa5076691b3e69028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d83aa579aaf043b28f48cbb3dd617799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd9db356d88e4d868cd37bd68c07da2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300bcc735f524e9f8d01cb118545a95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b11f7742077049e19dd654e97d6eedc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69588ce9172847848e87be637cf6cc17",
              "IPY_MODEL_ca5eafc2b80e4685811921c47831c0ab",
              "IPY_MODEL_6cf8e83090b34958bc8806bf37c7df40"
            ],
            "layout": "IPY_MODEL_e36d630467f54b99882f7cb66f3dfef3"
          }
        },
        "69588ce9172847848e87be637cf6cc17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2f4e0fc31884d2aaad8666d9c635cb0",
            "placeholder": "​",
            "style": "IPY_MODEL_3d112b8974304b84882d3e9b60cf8afc",
            "value": "100%"
          }
        },
        "ca5eafc2b80e4685811921c47831c0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_148c72d3238742cdb2d09f7b1c170b67",
            "max": 993,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72fae07ac400442693f8f20b771a2aba",
            "value": 993
          }
        },
        "6cf8e83090b34958bc8806bf37c7df40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46cb1130c0984d389644873322e6adf0",
            "placeholder": "​",
            "style": "IPY_MODEL_f744ea41af59456285a27d0cb603ab94",
            "value": " 993/993 [09:09&lt;00:00,  2.39it/s]"
          }
        },
        "e36d630467f54b99882f7cb66f3dfef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f4e0fc31884d2aaad8666d9c635cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d112b8974304b84882d3e9b60cf8afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "148c72d3238742cdb2d09f7b1c170b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72fae07ac400442693f8f20b771a2aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46cb1130c0984d389644873322e6adf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f744ea41af59456285a27d0cb603ab94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b85411498729470db0c5cef187297cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc224f43231241768d2ba97ee03eac5b",
              "IPY_MODEL_90fd2427122e4186a9283d6a9b148d8b",
              "IPY_MODEL_57b99be667ef4d98bbe2fbc292ed792e"
            ],
            "layout": "IPY_MODEL_5638d67baa094d968587aac3a0fa98a1"
          }
        },
        "dc224f43231241768d2ba97ee03eac5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bc0cb9418824bf093fed69e19256d0d",
            "placeholder": "​",
            "style": "IPY_MODEL_67acd334c95f4a19a271e49b31a6265a",
            "value": "100%"
          }
        },
        "90fd2427122e4186a9283d6a9b148d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23b55d818bb94052bb8515369401d4a9",
            "max": 993,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b272aa6d1cae4be3b58c3470a7a8b861",
            "value": 993
          }
        },
        "57b99be667ef4d98bbe2fbc292ed792e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb9298567bef4b0c86db8a0e047d3a93",
            "placeholder": "​",
            "style": "IPY_MODEL_72d0c56b66ce41019b06bd793f4fda4f",
            "value": " 993/993 [09:10&lt;00:00,  2.39it/s]"
          }
        },
        "5638d67baa094d968587aac3a0fa98a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc0cb9418824bf093fed69e19256d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67acd334c95f4a19a271e49b31a6265a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23b55d818bb94052bb8515369401d4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b272aa6d1cae4be3b58c3470a7a8b861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb9298567bef4b0c86db8a0e047d3a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d0c56b66ce41019b06bd793f4fda4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAYdSKAc5Jgk"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mYp_weS7SQ4",
        "outputId": "60248b33-f2e7-4678-f19e-b71f0fc3663b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('spoken_train-v1.1.json', 'r') as f:\n",
        "    squad = json.load(f)"
      ],
      "metadata": {
        "id": "RilckQBd7T53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad['data'][0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ88-UK27YLu",
        "outputId": "394289e9-1401-469f-a744-2f24598b72b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['title', 'paragraphs'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, group in enumerate(squad['data']):\n",
        "    if group['title'] == 'Greece':\n",
        "        gr = idx\n",
        "        print(group['title'])\n",
        "        print(gr)\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db_ho8Cm9OsN",
        "outputId": "def8d6d4-c410-4df1-ea8d-4287adfab2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greece\n",
            "202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squad['data'][186]['paragraphs'][0]['context']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "lLKZfSv298st",
        "outputId": "5a9a3574-4ef6-4b24-d794-2607c7bd07f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'napoleon bonaparte nato mean l l j e n french nap led the napa tea or nepali on deep wanna parte the fifteenth of august seventeen sixty nine to the fifth of may eighteen twenty one was a french military and political leader who rose to prominence during the french revolution and led several successful campaigns during the revolutionary war sir. as napoleon i he was emperor of the french from eighty know for intel eighteen fourteen and again in eighteen fifteen. napoleon dominated european in global affairs for more than a decade while leaving france against a series of coalitions in the napoleonic wars. he won most of these wars and the vast majority of his battles building a large empire that ruled over continental europe before its final collapse in eighteen fifteen. often considered one of the greatest commanders in history his wars in campaigns are studied at military schools worldwide. he also remains one of the most celebrated and controversial political figures in western history. in civil affairs napoleon had a major longterm impact by bringing liberal reforms to the territories that he conquered especially the low countries switzerland and large parts of modern italy and germany. he implemented fundamental liberal policies in france and throughout western europe no wine his lasting legal achievement the napoleonic code has been adopted in various forms by a quarter of the worlds legal systems from japan to put back.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(path):\n",
        "    with open(path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    for group in data['data']:\n",
        "        for paragraph in group['paragraphs']:\n",
        "            context = paragraph['context']\n",
        "            for qa in paragraph['qas']:\n",
        "                question = qa['question']\n",
        "                for answer in qa['answers']:\n",
        "                    answer_text = answer['text']\n",
        "                    answer_start = answer['answer_start']\n",
        "                    answer_end = answer_start + len(answer_text)\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append({\n",
        "                        'text': answer_text,\n",
        "                        'answer_start': answer_start,\n",
        "                        'answer_end': answer_end\n",
        "                    })\n",
        "\n",
        "    return contexts, questions, answers\n"
      ],
      "metadata": {
        "id": "esnlsQFf-DWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_contexts, train_questions, train_answers = read_data('spoken_train-v1.1.json')\n",
        "valid_contexts, valid_questions, valid_answers = read_data('spoken_test-v1.1.json')\n",
        "     \n"
      ],
      "metadata": {
        "id": "r5eQfFQ5-tmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'There are {len(train_questions)} questions')\n",
        "print(train_questions[986])\n",
        "print(train_answers[986])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QUtVrbe-zdv",
        "outputId": "4c6a6097-870f-48fc-c439-44ad19938987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 37111 questions\n",
            "What country borders south Estonia?\n",
            "{'text': 'latvia', 'answer_start': 262, 'answer_end': 268}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # check if answer is off by a character\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "            # when the gold label is off by one character\n",
        "            answer['answer_start'] = start_idx - 1\n",
        "            answer['answer_end'] = end_idx - 1\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "            # when the gold label is off by two characters\n",
        "            answer['answer_start'] = start_idx - 2\n",
        "            answer['answer_end'] = end_idx - 2\n",
        "\n",
        "    return answers\n"
      ],
      "metadata": {
        "id": "PMgGCUp1-4km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "doc_stride = 128  # Set the doc stride value as per your requirements\n",
        "\n",
        "def tokenize_examples(contexts, questions, max_length):\n",
        "    encodings = tokenizer(contexts, questions, truncation=True, padding=True, max_length=max_length, stride=doc_stride)\n",
        "    return encodings\n",
        "\n",
        "train_encodings = tokenize_examples(train_contexts, train_questions, max_length=512)\n",
        "valid_encodings = tokenize_examples(valid_contexts, valid_questions, max_length=512)\n"
      ],
      "metadata": {
        "id": "yaFLnJxF_dD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1oHS7w_AT1O",
        "outputId": "6212d03b-f109-416b-e3a9-1e88ce9eac6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_encodings = len(train_contexts)\n",
        "print(f'We have {no_of_encodings} context-question pairs')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0Z3uc8pAgPe",
        "outputId": "60505628-0058-40d4-e3f7-81f0a04db961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 37111 context-question pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(train_encodings['input_ids'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "a7si9OJ1BEG-",
        "outputId": "775f3f5d-b0a4-40c5-d037-03ecd3e41f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] architecturally the school has a catholic character. atop the main building school dome is the golden statue of the virgin mary. immediately in front of the main building in facing it is a copper statue of christ with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen fifty eight. at the end of the main drive and in a direct line that connects through three statues in the gold dome is as simple modern stone statue of mary. [SEP] what is in front of the notre dame main building? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i, answer in enumerate(answers):\n",
        "        start_pos = max(0, answer['answer_start'])\n",
        "        end_pos = max(0, answer['answer_end'] - 1)\n",
        "        start_positions.append(encodings.char_to_token(i, start_pos))\n",
        "        end_positions.append(encodings.char_to_token(i, end_pos))\n",
        "\n",
        "        # if start position is None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(valid_encodings, valid_answers)"
      ],
      "metadata": {
        "id": "2WIf8SYABHsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings['start_positions'][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m03Kq9vECcnp",
        "outputId": "6a2ccbc4-c920-4089-e7f4-f77b13ce14c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36, 11, 55, 107, 25, 21, 43, 67, 28, 22]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SQuAD_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, contexts, questions, answers, tokenizer, max_length=512, doc_stride=128):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "    self.doc_stride = doc_stride\n",
        "    self.contexts = contexts\n",
        "    self.questions = questions\n",
        "    self.answers = answers\n",
        "    self.encodings = self._get_encodings()\n",
        "\n",
        "  def _get_encodings(self):\n",
        "    encodings = self.tokenizer(\n",
        "      self.contexts,\n",
        "      self.questions,\n",
        "      truncation=True,\n",
        "      padding=True,\n",
        "      max_length=self.max_length,\n",
        "      stride=self.doc_stride\n",
        "    )\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, answer in enumerate(self.answers):\n",
        "      start_pos = max(0, answer['answer_start'])\n",
        "      end_pos = max(0, answer['answer_end'] - 1)\n",
        "      start_positions.append(encodings.char_to_token(i, start_pos))\n",
        "      end_positions.append(encodings.char_to_token(i, end_pos))\n",
        "\n",
        "      # if start position is None, the answer passage has been truncated\n",
        "      if start_positions[-1] is None:\n",
        "        start_positions[-1] = self.tokenizer.model_max_length\n",
        "      if end_positions[-1] is None:\n",
        "        end_positions[-1] = self.tokenizer.model_max_length\n",
        "\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "    return encodings\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    item['input_ids'] = item['input_ids'].squeeze()\n",
        "    item['attention_mask'] = item['attention_mask'].squeeze()\n",
        "    item['token_type_ids'] = item['token_type_ids'].squeeze()\n",
        "    item['start_positions'] = item['start_positions'].item()\n",
        "    item['end_positions'] = item['end_positions'].item()\n",
        "\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.contexts)\n",
        "\n",
        "train_dataset = SQuAD_Dataset(train_contexts, train_questions, train_answers, tokenizer)\n",
        "valid_dataset = SQuAD_Dataset(valid_contexts, valid_questions, valid_answers, tokenizer)\n"
      ],
      "metadata": {
        "id": "T77CNhFhDAg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "hfPsrSDqDT0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq_X6pNTFGqE",
        "outputId": "4dbbfebe-6df5-481b-8883-8def80771ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing BertForQuestionAnswering: ['predictions.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'albert.embeddings.token_type_embeddings.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.dense.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'albert.encoder.embedding_hidden_mapping_in.weight', 'predictions.LayerNorm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'albert.embeddings.word_embeddings.weight', 'albert.embeddings.LayerNorm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'albert.embeddings.LayerNorm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'predictions.LayerNorm.weight', 'albert.encoder.embedding_hidden_mapping_in.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'albert.embeddings.position_embeddings.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'qa_outputs.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'qa_outputs.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check on the available device - use GPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Working on {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4kl62CnGUTx",
        "outputId": "d9bf35c9-6985-4563-b7a3-c195046ded87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#update\n",
        "from transformers import AdamW\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "N_EPOCHS = 1\n",
        "optim = AdamW(model.parameters(), lr=3e-5)\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        loop.set_description(f'Epoch {epoch+1}')\n",
        "        loop.set_postfix(loss=loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "5bf8cd43369d40b4ab6ba017896ecff0",
            "953029952ede491e8bb20594ad46f1d3",
            "4fc8a26d9b204729b82b313c49d3b8a9",
            "45ca5e4557504af4a71aee721b80cf8b",
            "26de027d23964277b6a88387578a3f82",
            "c3e8713ebc884816b2930712e5c70564",
            "3ffdc4c8fc3544d0a281c774a8dd3545",
            "9c8e9e160ca4422fa5076691b3e69028",
            "d83aa579aaf043b28f48cbb3dd617799",
            "bd9db356d88e4d868cd37bd68c07da2e",
            "300bcc735f524e9f8d01cb118545a95e"
          ]
        },
        "id": "1EoNpHj5GeCc",
        "outputId": "82b047da-014d-4b62-c581-be18d793079f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2320 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bf8cd43369d40b4ab6ba017896ecff0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'DeepLearning'\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9kUZGQcHzHf",
        "outputId": "e11cddab-ad51-4528-a4b4-767cbe90af45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('DeepLearning/tokenizer_config.json',\n",
              " 'DeepLearning/special_tokens_map.json',\n",
              " 'DeepLearning/vocab.txt',\n",
              " 'DeepLearning/added_tokens.json',\n",
              " 'DeepLearning/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "acc = []\n",
        "\n",
        "for batch in tqdm(valid_loader):\n",
        "  with torch.no_grad():\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    start_true = batch['start_positions'].to(device)\n",
        "    end_true = batch['end_positions'].to(device)\n",
        "    \n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "    end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "\n",
        "    acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "    acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
        "\n",
        "acc = sum(acc)/len(acc)\n",
        "\n",
        "print(\"\\n\\nT/P\\tanswer_start\\tanswer_end\\n\")\n",
        "for i in range(len(start_true)):\n",
        "  print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
        "        f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "b11f7742077049e19dd654e97d6eedc5",
            "69588ce9172847848e87be637cf6cc17",
            "ca5eafc2b80e4685811921c47831c0ab",
            "6cf8e83090b34958bc8806bf37c7df40",
            "e36d630467f54b99882f7cb66f3dfef3",
            "e2f4e0fc31884d2aaad8666d9c635cb0",
            "3d112b8974304b84882d3e9b60cf8afc",
            "148c72d3238742cdb2d09f7b1c170b67",
            "72fae07ac400442693f8f20b771a2aba",
            "46cb1130c0984d389644873322e6adf0",
            "f744ea41af59456285a27d0cb603ab94"
          ]
        },
        "id": "XIR8cbq7dVq7",
        "outputId": "1a0ab331-5e6d-4530-8d21-9c14f66e2d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/993 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b11f7742077049e19dd654e97d6eedc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "T/P\tanswer_start\tanswer_end\n",
            "\n",
            "true\t59\t59\n",
            "pred\t51\t54\n",
            "\n",
            "true\t59\t60\n",
            "pred\t51\t54\n",
            "\n",
            "true\t59\t59\n",
            "pred\t51\t54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voKz_InRfttE",
        "outputId": "9e0d3435-7b9e-4960-c8d3-9c43b4ec1860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.9/dist-packages (from jiwer) (8.1.3)\n",
            "Collecting rapidfuzz==2.13.7\n",
            "  Downloading rapidfuzz-2.13.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.1 rapidfuzz-2.13.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jiwer\n",
        "\n",
        "model.eval()\n",
        "acc = []\n",
        "wer = []\n",
        "\n",
        "for batch in tqdm(valid_loader):\n",
        "    with torch.no_grad():\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_true = batch['start_positions'].to(device)\n",
        "        end_true = batch['end_positions'].to(device)\n",
        "        \n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        \n",
        "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
        "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
        "        \n",
        "        # Calculate WER\n",
        "        for i in range(len(start_true)):\n",
        "            true_text = tokenizer.decode(input_ids[i][start_true[i]:end_true[i]])\n",
        "            pred_text = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i]])\n",
        "            if true_text.strip() == \"\":\n",
        "                continue\n",
        "            wer.append(jiwer.wer(true_text, pred_text))\n",
        "        \n",
        "acc = sum(acc) / len(acc)\n",
        "wer = sum(wer) / len(wer)\n",
        "\n",
        "print(f'Accuracy: {acc:.4f}')\n",
        "print(f'WER: {wer:.4f}')\n",
        "\n",
        "print(\"\\n\\nT/P\\tanswer_start\\tanswer_end\\n\")\n",
        "for i in range(len(start_true)):\n",
        "    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
        "          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "b85411498729470db0c5cef187297cb2",
            "dc224f43231241768d2ba97ee03eac5b",
            "90fd2427122e4186a9283d6a9b148d8b",
            "57b99be667ef4d98bbe2fbc292ed792e",
            "5638d67baa094d968587aac3a0fa98a1",
            "0bc0cb9418824bf093fed69e19256d0d",
            "67acd334c95f4a19a271e49b31a6265a",
            "23b55d818bb94052bb8515369401d4a9",
            "b272aa6d1cae4be3b58c3470a7a8b861",
            "cb9298567bef4b0c86db8a0e047d3a93",
            "72d0c56b66ce41019b06bd793f4fda4f"
          ]
        },
        "id": "h9xAb4SAddBO",
        "outputId": "8e90d9cc-f861-49af-b981-06f949795570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/993 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b85411498729470db0c5cef187297cb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5956\n",
            "WER: 1.8495\n",
            "\n",
            "\n",
            "T/P\tanswer_start\tanswer_end\n",
            "\n",
            "true\t59\t59\n",
            "pred\t51\t54\n",
            "true\t59\t60\n",
            "pred\t51\t54\n",
            "true\t59\t59\n",
            "pred\t51\t54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(context, question):\n",
        "  inputs = tokenizer.encode_plus(question, context, return_tensors='pt').to(device)\n",
        "  outputs = model(**inputs)\n",
        "  \n",
        "  answer_start = torch.argmax(outputs[0])  \n",
        "  answer_end = torch.argmax(outputs[1]) + 1 \n",
        "  \n",
        "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "  \n",
        "  return answer\n",
        "\n",
        "def normalize_text(s):\n",
        "  \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
        "  import string, re\n",
        "  def remove_articles(text):\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    return re.sub(regex, \" \", text)\n",
        "  def white_space_fix(text):\n",
        "    return \" \".join(text.split())\n",
        "  def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return \"\".join(ch for ch in text if ch not in exclude)\n",
        "  def lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def exact_match(prediction, truth):\n",
        "    return bool(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "  pred_tokens = normalize_text(prediction).split()\n",
        "  truth_tokens = normalize_text(truth).split()\n",
        "  \n",
        "  # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "    return int(pred_tokens == truth_tokens)\n",
        "  \n",
        "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "  \n",
        "  # if there are no common tokens then f1 = 0\n",
        "  if len(common_tokens) == 0:\n",
        "    return 0\n",
        "  \n",
        "  prec = len(common_tokens) / len(pred_tokens)\n",
        "  rec = len(common_tokens) / len(truth_tokens)\n",
        "  \n",
        "  return round(2 * (prec * rec) / (prec + rec), 2)\n",
        "  \n",
        "def question_answer(context, question,answer):\n",
        "  prediction = get_prediction(context,question)\n",
        "  em_score = exact_match(prediction, answer)\n",
        "  f1_score = compute_f1(prediction, answer)\n",
        "\n",
        "  print(f'Question: {question}')\n",
        "  print(f'Prediction: {prediction}')\n",
        "  print(f'True Answer: {answer}')\n",
        "  print(f'Exact match: {em_score}')\n",
        "  print(f'F1 score: {f1_score}\\n')"
      ],
      "metadata": {
        "id": "Mdu7VcbMdxX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"Tetris (Russian: Тетрис)[a] is a puzzle video game created by the Soviet software engineer Alexey Pajitnov in 1984. \n",
        "It has been published by several companies for multiple platforms, most prominently during a dispute over the appropriation of the rights \n",
        "in the late 1980s. After a significant period of publication by Nintendo, the rights reverted to Pajitnov in 1996, who co-founded \n",
        "the Tetris Company with Henk Rogers to manage licensing. In Tetris, players complete lines by moving differently shaped pieces (tetrominoes), \n",
        "which descend onto the playing field. The completed lines disappear and grant the player points, and the player can proceed to fill \n",
        "the vacated spaces. The game ends when the uncleared lines reach the top of the playing field. The longer the player can delay this \n",
        "outcome, the higher their score will be. In multiplayer games, players must last longer than their opponents; in certain versions, \n",
        "players can inflict penalties on opponents by completing a significant number of lines. Some versions add variations on the rules, \n",
        "such as three-dimensional displays or a system for reserving pieces.\"\"\"\n",
        "\n",
        "\n",
        "questions = [\"What is the paragraph talking about?\",\n",
        "             \"What is Tetris?\",\n",
        "             \"When was it created?\",\n",
        "             \"Who created it?\",\n",
        "             \"How the game is played?\",\n",
        "             \"When the game ends?\"]\n",
        "\n",
        "answers = [\"Tetris\", \"puzzle video game\", \"1984\", \n",
        "           \"Alexey Pajitnov\", \"complete lines by moving differently shaped pieces\", \n",
        "           \"uncleared lines reach the top of the playing field\"]\n",
        "\n",
        "for question, answer in zip(questions, answers):\n",
        "  question_answer(context, question, answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqd_8EuZdx7X",
        "outputId": "cd1253b4-c4b7-4fc8-8487-7f3e0e841a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the paragraph talking about?\n",
            "Prediction: puzzle video game created by the soviet software engineer alexey pajitnov in 1984. it has been published by several companies for multiple platforms, most prominently during a dispute over the appropriation of the rights in the late 1980s. after a significant period of publication by nintendo, the rights reverted to pajitnov in 1996, who co - founded the tetris company with henk rogers to manage licensing. in tetris, players complete lines by moving differently shaped pieces ( tetrominoes ), which descend onto the playing field\n",
            "True Answer: Tetris\n",
            "Exact match: False\n",
            "F1 score: 0.03\n",
            "\n",
            "Question: What is Tetris?\n",
            "Prediction: puzzle video game created by the soviet software engineer alexey pajitnov in 1984. it has been published by several companies for multiple platforms, most prominently during a dispute over the appropriation of the rights in the late 1980s. after a significant period of publication by nintendo, the rights reverted to pajitnov in 1996, who co - founded the tetris company with henk rogers to manage licensing. in tetris, players complete lines by moving differently shaped pieces ( tetrominoes ), which descend onto the playing field. the completed lines disappear and grant the player points, and the player can proceed to fill the vacated spaces. the game ends when the uncleared lines reach the top of the playing field. the longer the player can delay this outcome, the higher their score will be. in multiplayer games\n",
            "True Answer: puzzle video game\n",
            "Exact match: False\n",
            "F1 score: 0.05\n",
            "\n",
            "Question: When was it created?\n",
            "Prediction: 1984\n",
            "True Answer: 1984\n",
            "Exact match: True\n",
            "F1 score: 1.0\n",
            "\n",
            "Question: Who created it?\n",
            "Prediction: alexey pajitnov\n",
            "True Answer: Alexey Pajitnov\n",
            "Exact match: True\n",
            "F1 score: 1.0\n",
            "\n",
            "Question: How the game is played?\n",
            "Prediction: puzzle video game created by the soviet software engineer alexey pajitnov in 1984. it has been published by several companies for multiple platforms, most prominently during a dispute over the appropriation of the rights in the late 1980s. after a significant period of publication by nintendo, the rights reverted to pajitnov in 1996, who co - founded the tetris company with henk rogers to manage licensing. in tetris, players complete lines by moving differently shaped pieces ( tetrominoes ), which descend onto the playing field\n",
            "True Answer: complete lines by moving differently shaped pieces\n",
            "Exact match: False\n",
            "F1 score: 0.17\n",
            "\n",
            "Question: When the game ends?\n",
            "Prediction: tetris ( russian : тетрис ) [ a ] is a puzzle video game created by the soviet software engineer alexey pajitnov in 1984. it has been published by several companies for multiple platforms, most prominently during a dispute over the appropriation of the rights in the late 1980s. after a significant period of publication by nintendo, the rights reverted to pajitnov in 1996, who co - founded the tetris company with henk rogers to manage licensing. in tetris, players complete lines by moving differently shaped pieces ( tetrominoes ), which descend onto the playing field\n",
            "True Answer: uncleared lines reach the top of the playing field\n",
            "Exact match: False\n",
            "F1 score: 0.1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQBDHw02f1Zo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}